{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業\n",
    "\n",
    "\n",
    "\n",
    "閱讀以下兩篇文獻，了解決策樹原理，並試著回答後續的問題\n",
    "- [決策樹 (Decision Tree) - 中文](https://medium.com/@yehjames/%E8%B3%87%E6%96%99%E5%88%86%E6%9E%90-%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E7%AC%AC3-5%E8%AC%9B-%E6%B1%BA%E7%AD%96%E6%A8%B9-decision-tree-%E4%BB%A5%E5%8F%8A%E9%9A%A8%E6%A9%9F%E6%A3%AE%E6%9E%97-random-forest-%E4%BB%8B%E7%B4%B9-7079b0ddfbda)\n",
    "- [how decision tree works - 英文](http://dataaspirant.com/2017/01/30/how-decision-tree-algorithm-works/)\n",
    "\n",
    "1. 在分類問題中，若沒有任何限制，決策樹有辦法在訓練時將 training loss 完全降成 0 嗎？\n",
    "2. 決策樹只能用在分類問題嗎？還是可以用來解決回歸問題？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1.ANS:\n",
    "    https://github.com/scutan90/DeepLearning-500-questions/blob/master/ch02_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/%E7%AC%AC%E4%BA%8C%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.md\n",
    "        \n",
    "    \n",
    "    算法\t优点\t缺点\n",
    "Bayes 贝叶斯分类法\t1）所需估计的参数少，对于缺失数据不敏感。\n",
    "2）有着坚实的数学基础，以及稳定的分类效率。\t1）需要假设属性之间相互独立，这往往并不成立。（喜欢吃番茄、鸡蛋，却不喜欢吃番茄炒蛋）。\n",
    "2）需要知道先验概率。\n",
    "3）分类决策存在错误率。\n",
    "Decision Tree决策树\t1）不需要任何领域知识或参数假设。\n",
    "2）适合高维数据。\n",
    "3）简单易于理解。\n",
    "4）短时间内处理大量数据，得到可行且效果较好的结果。\n",
    "5）能够同时处理数据型和常规性属性。\t1）对于各类别样本数量不一致数据，信息增益偏向于那些具有更多数值的特征。\n",
    "2）易于过拟合。\n",
    "3）忽略属性之间的相关性。\n",
    "4）不支持在线学习。\n",
    "\n",
    "http://dataaspirant.com/2017/01/30/how-decision-tree-algorithm-works/\n",
    "    \n",
    "Overfitting\n",
    "Overfitting is a practical problem while building a decision tree model. The model is having an issue of overfitting is considered when the algorithm continues to go deeper and deeper in the to reduce the training set error but results with an increased test set error i.e, Accuracy of prediction for our model goes down. It generally happens when it builds many branches due to outliers and irregularities in data.\n",
    "\n",
    "Two approaches which we can use to avoid overfitting are:\n",
    "\n",
    "Pre-Pruning\n",
    "Post-Pruning\n",
    "Pre-Pruning\n",
    "In pre-pruning, it stops the tree construction bit early. It is preferred not to split a node if its goodness measure is below a threshold value. But it’s difficult to choose an appropriate stopping point.\n",
    "\n",
    "Post-Pruning\n",
    "In post-pruning first, it goes deeper and deeper in the tree to build a complete tree. If the tree shows the overfitting problem then pruning is done as a post-pruning step. We use a cross-validation data to check the effect of our pruning. Using cross-validation data, it tests whether expanding a node will make an improvement or not.\n",
    "\n",
    "If it shows an improvement, then we can continue by expanding that node. But if it shows a reduction in accuracy then it should not be expanded i.e, the node should be converted to a leaf node.\n",
    "\n",
    "Decision Tree Algorithm Advantages and Disadvantages\n",
    "Advantages:\n",
    "Decision Trees are easy to explain. It results in a set of rules.\n",
    "It follows the same approach as humans generally follow while making decisions.\n",
    "Interpretation of a complex Decision Tree model can be simplified by its visualizations. Even a naive person can understand logic.\n",
    "The Number of hyper-parameters to be tuned is almost null.\n",
    "Disadvantages:\n",
    "There is a high probability of overfitting in Decision Tree.\n",
    "Generally, it gives low prediction accuracy for a dataset as compared to other machine learning algorithms.\n",
    "Information gain in a decision tree with categorical variables gives a biased response for attributes with greater no. of categories.\n",
    "Calculations can become complex when there are many class labels.\n",
    " \n",
    "\n",
    "2.可以用在回歸問題,但需要將資料離散化,訂一個thresold value,大於他就是A,小於就是B,就可以轉成分類問題了"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
